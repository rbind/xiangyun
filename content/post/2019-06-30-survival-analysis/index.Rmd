---
title: "影响入院等待时间的因素分析"
author: "黄湘云"
date: '2019-06-30'
slug: survival-analysis
categories:
  - 统计模型
tags:
  - 生存分析
draft: true
math: true
output:
  blogdown::html_page:
    toc: true
link-citations: true
description: "waitingtime 作为研究变量，表示的是患者在医生诊断之后，需要等待多长时间来住院。要求探索下影响入院等待时间的因素，搭建模型预测等待入院时间，并给出合理解释，用两种预测模型。"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, message = FALSE)

options(conflicts.policy = list(warn = FALSE))
library(dplyr)
```

## 本文概览

1.  分析目标：患者在医生诊断后，预测需要等待多久时间来住院，探索影响入院等待时间的因素

1.  分析思路：

  1.  探索影响入院等待时间的因素
      -  根据相关性寻找原因，用回归分析
      -  影响等待时间的因素，时间长一点短一点，只要来住院，这个问题似乎更重要
  1.  更加准确地预测等待时间
	    -  预测问题，可用机器学习的方法

1.  分析流程

   -  弄清楚各个指标的含义，特别是离群值和缺失值的实际意义
   -  描述性统计分析，从数据中获得初步认识，为数据建模和结果解释做依据
   -  建立广义线性模型和机器学习模型
   -  模型评估、选择、结果分析和解释

1.  分析目标

   -  患者在医生诊断后，需要等待多久时间来住院，探索影响入院等待时间的因素
   -  根据观测结果和相关性寻找原因的问题，属于回归分析
   -  更加准确地预测等待时间（时间长一点短一点只有来住院）
   -  影响等待时间的因素（这个问题似乎更重要）

1.  分析流程

   -  弄清楚各个指标的含义，包括离群值和缺失值的实际意义
   -  描述性统计分析，从数据中获得进一步认识，为数据建模做依据
   -  建立模型，模型评估和选择
   -  模型结果分析和解释


## 数据操作

```{r,echo=TRUE}
dat <- read.csv(file = "data/hospital_waiting_time.csv", 
                header = TRUE, check.names = FALSE, fileEncoding = "GBK")
dat$开住院条日期 <- factor(dat$开住院条日期)
dat$性别 <- factor(dat$性别)
dat$入院疾病分类 <- factor(dat$入院疾病分类)
dat$入院目的 <- factor(dat$入院目的)
dat$住院类别 <- factor(dat$住院类别)
dat$入院病情 <- factor(dat$入院病情)
dat$Doctor <- factor(dat$Doctor)
tibble::as_tibble(dat)
```

- 门诊次：挂号看诊次数
- 住院次：办理住院的次数
- 开住院条的日期：住院天数


```{r}
plot(dat$门诊次) # 为什么有几百次的门诊
plot(dat$开住院条日期) # 实际还有一类是缺失值
```

1. 住院次数特别多的人，比如10次以上，是比较异常的，情况比较少，两种住院类型都有，等待时间比较短

```{r}
subset(dat, 住院次 > 10)
plot(dat$住院次[dat$住院次 < 10], ylab = "住院次数", xlab = "")
```

1. 等待时间为0，说明情况紧急，急需住院，也可能是着急占床位，入院病情是否相符。响应变量近似看作服从对数正态分布，取值为0，对应的密度也是0，其实可以去掉

```{r}
subset(dat, WaitingTime == 0)[1:6, ]
```

1. 开住院条日期缺失，说明可能没办住院手续，等待时间如何分布

```{r}
boxplot(subset(dat, is.na(开住院条日期), select = "WaitingTime"))
```

- 去掉等待时间为 0，门诊次为 0 的记录，住院次数特别多的情况
- 年龄标准化，门诊次对数变换，开住院条日期缺失单独作为一类
- 将罕见的情况，对模型来说，可以认为是异常情况

```{r,echo=TRUE}
# 去掉异常值
sub_dat <- subset(dat, WaitingTime != 0 & 门诊次 != 0 & 住院次 <= 10)
# 年龄标准化，门诊次对数变换
sub_dat <- transform(sub_dat, 年龄 = (年龄 - mean(年龄)) / sd(年龄), 门诊次 = log(门诊次), 开住院条日期 = ifelse(is.na(开住院条日期), 0, 开住院条日期))
tibble::as_tibble(sub_dat)
```

## 数据探索

### 等待时间的分布

- 等待时间的是偏态分布，右偏

```{r}
library(ggplot2)
gWT1 <- ggplot(data = sub_dat, aes(WaitingTime)) +
  geom_histogram()
gWT2 <- ggplot(data = sub_dat, aes(x = factor(1), y = WaitingTime)) +
  geom_jitter()
gWT3 <- ggplot(data = sub_dat, aes(x = factor(1), y = WaitingTime)) +
  geom_boxplot()
gWT4 <- ggplot(data = sub_dat, aes(x = factor(1), y = WaitingTime)) +
  geom_violin()
library(cowplot)
plot_grid(gWT1, gWT2, gWT3, gWT4, label_size = 12)
```

- 对数化等待时间的分布

```{r}
ggplot(data = sub_dat, aes(log(WaitingTime))) +
  geom_histogram()
```

### 等待时间和医生及入院病情的关系

- 2号病情属于比较紧急的情况，都是立即办住院，和医生的类型无关，这也符合常识

```{r}
ggplot(data = dat, aes(x = Doctor, y = WaitingTime, color = Doctor)) +
  geom_jitter() +
  facet_grid(~入院病情)
```

按医生类别和入院病情分组平均

```{r}
aggregate(WaitingTime ~ Doctor + 入院病情, data = sub_dat, mean)
```

### 等待时间和住院类别及入院目的的关系

- 2号和3号入院目的的等待时间短，1号住院类别相比2号短

```{r}
ggplot(data = sub_dat, aes(x = 住院类别, y = WaitingTime, color = 住院类别)) +
  geom_jitter() +
  facet_grid(~入院目的)
```

按入院类别和入院目的分组平均

```{r}
aggregate(WaitingTime ~ 住院类别 + 入院目的, data = sub_dat, mean)
```

### 等待时间和病人性别及年龄的关系

- 和性别关系不大
- 年龄跨度从2岁到98岁

```{r}
g3 <- ggplot(data = dat, aes(x = 年龄, y = WaitingTime)) +
  geom_point() +
  facet_grid(~性别)

g4 <- ggplot(data = dat, aes(x = 年龄, y = log(WaitingTime))) +
  geom_point() +
  facet_grid(~性别)

plot_grid(g3, g4, label_size = 12)
```

## 广义线性模型

```{r,echo=TRUE}
gamma_glm_fit <- glm(
  data = sub_dat, formula = WaitingTime ~ .,
  family = Gamma(link = "inverse") # or Gamma(link = "log")
)
AIC(gamma_glm_fit)
summary(gamma_glm_fit)
```

虽然预测效果差，但是不妨碍去找影响因素

```{r}
#| cache: true
#| eval: false

library(brms)
log_glm_brm_fit1 <- brm(
  data = sub_dat, formula = WaitingTime ~ .,
  family = lognormal(link = "identity", link_sigma = "log"),
  refresh = 0,
  backend = "rstan"
)
log_glm_brm_fit1
loo_fit1 <- loo(log_glm_brm_fit1) # LOOIC 越小越好

log_glm_brm_fit2 <- brm(
  data = sub_dat, formula = WaitingTime ~ .,
  family = Gamma(link = "log"), 
  refresh = 0,
  backend = "rstan"
)
log_glm_brm_fit2
loo_fit2 <- loo(log_glm_brm_fit2) # LOOIC 越小越好
# Leave-one-out cross-validation
loo_compare(loo_fit1, loo_fit2, criterion = "waic")
```

假定等待时间服从伽马分布比服从对数正态分布拟合效果好一些

### 结果解释

1. 是男是女对等待时间的贡献水平是基本一样的，性别这个变量在这个数据集或者说这类病中影响不大；
1. 年龄对等待时间是正的贡献，年龄越大，等待时间越长；
1. 以疾病类型1为参照，2号疾病有更大影响，相对1号，等待时间更长，3号和4号疾病反之；
1. 以1号入院目的为参照，2号入院目的对等待时间是负的贡献，即出现2号入院目的，等待时间会更短；
1. 住院类型1号和2号都对等待时间有正的贡献；
1. 相比于2号医生，3号医生对等待时间是正的贡献，4号医生是负的贡献，说明患者去4号医生那看病后，更快去办入院手续，从相对值来看，这位医生很可能挂专家门诊，并且比三号医生更加有名。

### 模型评估

使用机器学习的算法，需要把数据集做拆分为训练集和测试集，对测试集做10折交叉验证，用平均均方误差衡量模型的性能。

```{r}
# n 样本量 z 折数 seed 设置抽样的随机数种子
# 将样本随机地分成 z 份
cv <- function(n = 100, z = 9, seed = 2019) {
  set.seed(seed)
  idx_seq <- rep(1:z, ceiling(n / z))[1:n] # 初始化 1-9 组成的指标序列，长度等于样本量
  reorder_idx_seq <- sample(x = idx_seq, size = n, replace = FALSE) # 对指标序列 idx_seq 重排
  mm <- vector("list", z) # 初始化列表，存储原序列的下标集
  for (i in 1:z) {
    mm[[i]] <- (1:n)[reorder_idx_seq == i] # 第i折对应的原序列的下标集
  }
  return(mm)
}
n <- nrow(sub_dat)
kfold <- 10
idx <- cv(n, kfold, seed = 2019)
D <- 1 # WaitingTime 在第 1 列
# 初始化向量用于存储均方误差
MSE <- rep(0, kfold)
```

## 模型比较

### 伽马广义线性模型


```{r}
for (i in 1:kfold) {
  m <- idx[[i]]
  M <- mean((sub_dat[m, D] - mean(sub_dat[m, D]))^2) # 用平均值预测  WaitingTime 的均方误差
  log_lm_fit <- glm(
    data = sub_dat[-m, ], formula = WaitingTime ~ .,
    family = Gamma(link = "inverse")
  )
  MSE[i] <- mean((sub_dat[m, D] - predict(log_lm_fit, sub_dat[m, ]))^2) / M # 测试集上算均方误差
}
mean(MSE) # 1.420639
```



### 决策树回归


```{r}
library(rpart)
rpart_fit <- rpart(data = sub_dat, WaitingTime ~ .)
plot(rpart_fit)
library(rpart.plot)
rpart.plot(rpart_fit, type = 2, faclen = 0)

for (i in 1:kfold) {
  m <- idx[[i]]
  M <- mean((sub_dat[m, D] - mean(sub_dat[m, D]))^2) # 用平均值预测  WaitingTime 的均方误差
  rpart_fit <- rpart(data = sub_dat[-m, ], WaitingTime ~ .)
  MSE[i] <- mean((sub_dat[m, D] - predict(rpart_fit, sub_dat[m, ]))^2) / M # 测试集上算均方误差
}
# 相对均方误差 越小越好
mean(MSE) # 10 折下来的平均结果 0.9805241
```

### 随机森林

```{r}
library(randomForest)

for (i in 1:kfold) {
  m <- idx[[i]]
  M <- mean((sub_dat[m, D] - mean(sub_dat[m, D]))^2) # 用平均值预测  WaitingTime 的均方误差
  rf_fit <- randomForest(data = sub_dat[-m, ], WaitingTime ~ .)
  MSE[i] <- mean((sub_dat[m, D] - predict(rf_fit, sub_dat[m, ]))^2) / M # 测试集上算均方误差
}
# 相对均方误差 越小越好
mean(MSE) # 10 折下来的平均结果 0.9859137

rf_fit <- randomForest(
  x = sub_dat[, -1], y = sub_dat[, 1],
  importance = TRUE, proximity = TRUE
)
# 变量重要性
rf_fit$importance
```

两列都是数值越大，变量越重要


### 支持向量机

```{r}
library(e1071)
# x 全部得是数值型的
svm_fit <- svm(data = sub_dat, WaitingTime ~ .)

for (i in 1:kfold) {
  m <- idx[[i]]
  M <- mean((sub_dat[m, D] - mean(sub_dat[m, D]))^2) # 用平均值预测  WaitingTime 的均方误差
  svm_fit <- svm(data = sub_dat[-m, ], WaitingTime ~ .)
  MSE[i] <- mean((sub_dat[m, D] - predict(svm_fit, sub_dat[m, ]))^2) / M # 测试集上算均方误差
}
# 相对均方误差 越小越好
mean(MSE) # 10 折下来的平均结果 1.031385 效果非常差，不能接受
```



### 神经网络


```{r}
library(nnet)
# library(caret)

set.seed(2019)

comp_grid <- expand.grid(
  .decay = c(0.5, 0.4, 0.3, 0.2, 0.1, 0.05),
  .size = c(4, 5, 6, 7, 8)
)
nnet_fit <- caret::train(
  WaitingTime / max(WaitingTime) ~ .,
  data = sub_dat,
  method = "nnet", maxit = 1000,
  tuneGrid = comp_grid, trace = FALSE
)

print(nnet_fit) # size = 5 and decay = 0.05

for (i in 1:kfold) {
  m <- idx[[i]]
  M <- mean((sub_dat[m, D] - mean(sub_dat[m, D]))^2) # 用平均值预测  WaitingTime 的均方误差
  nnet_fit <- nnet(data = sub_dat[-m, ], WaitingTime / max(sub_dat[, D]) ~ ., size = 5, decay = 0.05, trace = FALSE)
  MSE[i] <- mean((sub_dat[m, D] - predict(nnet_fit, sub_dat[m, ]) * max(sub_dat[, D]))^2) / M # 测试集上算均方误差
}
# 相对均方误差 越小越好
mean(MSE) # 10 折下来的平均结果 0.9601197
```


### Box-Cox 变换

Box-Cox 变换后，再做线性拟合


```{r}
library(MASS)
b <- boxcox(WaitingTime ~ ., data = sub_dat)
i <- which(b$y == max(b$y))
b$x[i] # 选 lambda
```

选好 lambda 先拟合线性模型做 baseline

```{r}
lm_fit <- lm(WaitingTime^0.14 ~ ., data = sub_dat)
step_lm_fit <- step(lm_fit, trace = FALSE)
AIC(step_lm_fit)
summary(step_lm_fit)
```

```{r}
for (i in 1:kfold) {
  m <- idx[[i]]
  M <- mean((sub_dat[m, D] - mean(sub_dat[m, D]))^2) # 用平均值预测  WaitingTime 的均方误差
  lm_fit <- lm(WaitingTime^0.14 ~ ., data = sub_dat[-m, ])
  MSE[i] <- mean((sub_dat[m, D] - predict(nnet_fit, sub_dat[m, ]) * max(sub_dat[, D]))^2) / M # 测试集上算均方误差
}
# 相对均方误差 越小越好
mean(MSE) # 10 折下来的平均结果 0.9404893
```

